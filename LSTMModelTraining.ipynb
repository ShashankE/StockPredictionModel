{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Welcome to my LSTM Model! Hit run and watch the step-by-step training of my stock prediction Model\n\nAt the end you will get a LSTM_model file which can be plugged into a different script @/stockpredictionapp.ipynb which can be applied to all stocks and not just the 9 tested here!","metadata":{"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport yfinance as yf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\n\n# Define the tickers to fetch data for\ntickers = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA', 'ADBE', 'INTC', 'CSCO', 'IBM']\n\n# Fetch data for each ticker using Yahoo Finance API\ndata = {}\nfor ticker in tickers:\n    stock = yf.Ticker(ticker)\n    data[ticker] = stock.history(period='5y')['Close']\n\n# Combine data for all stocks into a single dataset\ndf = pd.concat(data.values(), axis=1, keys=data.keys())\n\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This data will now be shaped so it can be inputted into the machine learning model!\n\nUsing MinMaxScaler we are able to normalize our dataframe into managble variables which can be inputted into the model","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Datasets\n\nWhat is lookback?\n\n    It is the value of N past time steps which the dataset will input into the neural network to predict the next value of the time-series.\n    \nThis code will take that value and create datasets for testing and training the prediction values and the model.\n    \n    ","metadata":{}},{"cell_type":"code","source":"# create input/output arrays for training and testing data\ndef create_dataset(data, lookback):\n    X, Y = [], []\n    for i in range(lookback, len(data)):\n        X.append(data[i-lookback:i, 0])\n        Y.append(data[i, 0])\n    return np.array(X), np.array(Y)\n\nlookback = 60\nx_train, y_train = create_dataset(train_data, lookback)\nx_test, y_test = create_dataset(test_data, lookback)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Time to build the model!\n1. creating the models\n2. compliing the model\n3. fitting the data into the model","metadata":{}},{"cell_type":"code","source":"\n# Build Model\nmodel = Sequential() \nmodel.add(LSTM(50, return_sequences=True, input_shape=(lookback, 1)))\nmodel.add(LSTM(50, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\n# compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# train the model\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heres what our model looks like so far!","metadata":{}},{"cell_type":"code","source":"print(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now that the model is created, we can start to make our predictions!\n","metadata":{}},{"cell_type":"code","source":"# make predictions and evaluate performance\npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\nmae = mean_absolute_error(y_test, predictions)\nprint('Mean Absolute Error:', mae)\n\n# pickle data\nmodel.save(\"lstm_model_l1\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}